<h2 style="text-align: center; margin-top: -150px; color: #3498db;">Research</h2>

<!-- Research interests section -->
<style>
    .research_box {
        padding: 15px;
        background-color: #1a1a1a;
        border: 2px solid #5c00dd;
        box-shadow: 0 0 10px rgba(0, 0, 0, 0.3);
        transition: all 0.3s ease;
        color: #fff;
        font-family: 'Courier New', Courier, monospace;
        width: 92%; /* Set default width */
        margin: 0 auto; /* Center the box on larger screens */
    }

    .research_box:hover {
        border-color: #3498db;
        background-color: #262626;
        transform: scale(1.02);
    }

    /* Grid container for 2x2 layout */
    .grid-container {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        width: 100%; /* Full width */
        gap: 20px; /* Spacing between boxes */
        margin-top: 20px;
    }

    /* Mobile styles */
    @media (max-width: 768px) { /* Adjust the max-width as needed for your design */
        .grid-container {
            grid-template-columns: 1fr; /* 1 box per row */
        }

        .research_box {
            width: 92%; /* Each box takes 92% of the width */
            margin: 10px auto; /* Add some margin on top and bottom */
        }
    }
</style>


<div style="padding-left: 5%; padding-right: 5%;">
    <div style="width: 100%; padding: 8px; margin-bottom: 20px; text-align: center; font-size: large;">
        Here's some information about the work I do, that I find particularly interesting.<br/>Send me a message if we have overlapping interests.
    </div>

    <!-- Grid container for 2x2 layout -->
    <div class="grid-container">
        <div class="research_box"><strong>üéØ Zero-Shot Generalisation</strong><br>Show a monkey how to stack some bricks, and it‚Äôll ace the job no matter the shape, color, or pose. Teach the same trick to a DL model, and watch it have an aneurism because the colour of the brick changed. Personally, I'm not a fan of drowning models in heaps of training data, so how do we craft <strong>domain-invariant</strong> policies?‚Äù
            <br><br>
            <a href="https://arxiv.org/abs/2111.09794">Zero-shot Generalisation in DRL Survey</a> - really nice survey on this topic by the lot in DARK labs, UCL.<br>
            <a href="https://arxiv.org/abs/2107.12808">Open-Ended Learning</a> - I can't tell if I love or hate this paper yet, but I know you have to read it.<br>
            <a href="https://ieeexplore.ieee.org/document/9847099?arnumber=9847099">Domain Generalisation Survey</a> - a broader look at the problem of domain invariance.<br>
            <a href="https://arxiv.org/abs/2202.00104">Generalisation in Cooperative MARL</a> - an interesting look into comnbinatorial generalisation.
        </div>

        <div class="research_box"><strong>üß† Representation Learning</strong><br> When you learn something new, what does it even mean to understand it? It's something we do quasi-proactively; half the time, it's like a mental magic trick we perform almost on autopilot. This notion of learning in DL is usually achieved with representation learning, where a model learns representations from raw data. This currently works pretty dang well in single-domain supervised learning tasks, but how can we create representations that are more representative of the mess of a world we live in?
            <br><br>
            <a href="https://arxiv.org/abs/2301.08243">I-JEPA</a> - can you even talk about representation learning without mentioning Yann's work?<br>
            <a href="https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/">V-JEPA</a> - V0.2 of Yann's vision.<br>
            <a href="https://arxiv.org/pdf/1206.5538">Representation Learning Review</a> - old but gold.<br>
            <a href="https://ieeexplore.ieee.org/document/8715409">Multimodal Representation Learning</a> - what it says on the tin.
        </div>

        <div class="research_box"><strong>üîÑ Continual Learning</strong><br> Is there a <a href="https://link.springer.com/content/pdf/10.1007/978-3-319-15524-1.pdf">myth of the objective</a>? Does it even exist, or are we just chasing shadows? This leads onto the real question: how do we design an algorithm that will last for the next thousand years?
            <br><br>
            <a href="https://arxiv.org/abs/1909.08383">Continual Learning Survey</a><br>
            <a href="https://arxiv.org/abs/2302.00487">Another Continual Learning Survey</a> - Both of these surveys are great<br>
            <a href="https://www.youtube.com/watch?v=Ugp1osXLEd4">A Definition of Continual Learning</a> - a definition of continual DRL by one of my PhD supervisors.
        </div>

        <div class="research_box"><strong>üìú Magnus Finis¬†</strong><br> Stop doing research for the sake of research. What was the end goal again? How do we get there? Well, here are a few interesting takes.
            <br><br>
            <a href="https://www.cs.ox.ac.uk/activities/ieg/e-library/sources/t_article.pdf">Can Machines Think?</a> - the man himself.<br>
            <a href="https://arxiv.org/abs/2208.11173">The Alberta Plan</a> - Richard Sutton's take.<br>
            <a href="https://openreview.net/pdf?id=BZ5a1r-kVsf">Path to AMI</a> - Yann LeCun's take.<br>
            <a href="https://openreview.net/pdf?id=Sv7DazuCn8">The Big World Hypothesis</a> - short but sweet.
        </div>
    </div>
</div>
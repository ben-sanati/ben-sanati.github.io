<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
    <!--<head>-->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="Hey, I'm Ben" />
    <meta name="author" content="" />
    <meta name="keywords" content="DL, DRL, MARL, ZSG, Continual Learning" />
    <link rel="canonical" href="http://0.0.0.0:4000/">
    <link rel='shortcut icon' href='/assets/img/favicon.ico' type='image/x-icon'>
    <title>Ben Sanati  | Ben Sanati</title>
    
    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <!--    <link href="/assets/css/bootstrap.min.css" rel="stylesheet">-->
    
    <!-- Custom CSS -->
    <!-- Lower body under about -->
    <link href="/assets/css/grayscale.css" rel="stylesheet">
    <!-- Timeline -->
    <link href="/assets/css/timeline.css" rel="stylesheet">
    <!-- Research details section -->
    <link href="/assets/css/particles.css" rel="stylesheet">
    
    <div id="particles-js" text-align="center"></div>
        <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    <i class="fa fa-bars"></i>
                </button>
                
                    <a class="navbar-brand page-scroll" href="#page-top">
                        Ben Sanati
                    </a>
                
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>

                    
                        <li><a class="page-scroll" href="#research">research</a></li>
                        <li><a class="page-scroll" href="#experience">experience</a></li>
                        <li><a href="http://0.0.0.0:4000/cv/index.html">cv</a></li>
                    

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    
<script src="/assets/js/jquery.js"></script> <!-- jQuery -->
<script src="/assets/js/bootstrap.min.js"></script><!-- Bootstrap Core JavaScript -->
<script src="/assets/js/jquery.easing.min.js"></script> <!-- Plugin JavaScript -->
<script src="/assets/js/grayscale.js"></script> <!-- Custom Theme JavaScript -->
<script src="/assets/js/jquery.dataTables.min.js"></script>
<link href="https://cdn.datatables.net/buttons/2.2.2/css/buttons.dataTables.min.css" rel="stylesheet">
<script src="https://cdn.datatables.net/buttons/2.2.2/js/dataTables.buttons.min.js"></script>

<script src="/assets/js/scrollreveal.min.js"></script>
<script src="/assets/js/toc.js"></script>
<script>
    window.sr = ScrollReveal();
    sr.reveal('.timeline-panel');
    sr.reveal('.timeline-image');
</script>

<script src="/assets/js/particles.min.js"></script>
<script>
    particlesJS.load('particles-js', '/assets/js/particles.json', function () {
        console.log('callback - particles.js config loaded');
    });
</script>

    <script src="https://kit.fontawesome.com/ace312f182.js" crossorigin="anonymous"></script>

    <!-- Styling Tables -->
    <link href="https://cdn.datatables.net/1.10.19/css/jquery.dataTables.min.css" rel="stylesheet">
    <link href="/assets/css/lowercase.css" rel="stylesheet">
</head>
<!-- Intro Header -->
<header class="intro">
    <div class="intro-body">
        <div class="container">
            <div class="row align-center">
                <!-- Left side: Image and Text -->
                <div class="left-container">
                    <div class="image-container">
                        <img src="http://0.0.0.0:4000/assets/img/avatar.jpeg" class="profile-image">
                    </div>
                    <h1 class="intro-text-left" style="margin-top: 20px;">
                        PhD Student<br/>University of Edinburgh
                    </h1>
                    <ul class="list-inline social-buttons" style="margin-top: 5px;">
                        <li><a href="mailto:s2719541@ed.ac.uk"><i class="fa fa-envelope fa-fw"></i></a></li>
                        <li><a href="http://0.0.0.0:4000/cv/index.html">cv</a></li>
                        <li><a href="https://github.com/ben-sanati"><i class="fa fa-github fa-fw"></i></a></li>
                        <li><a href="https://www.linkedin.com/in/benjamin-sanati/"><i class="fa fa-linkedin fa-fw"></i></a></li>
                    </ul>
                    <br>
                    <p class="intro-text-left">
                        I'm interested in DRL, MARL,<br/>ZSG, and continual learning.
                    </p>
                </div>
            </div>
        </div>
    </div>
</header>

<style>
    .left-container {
        padding-left: 0 !important;
        margin-left: 0 !important;
        width: 30% !important; /* Width of the left container */
    }

    .image-container {
        text-align: center;
    }

    .profile-image {
        width: 50%; /* Image takes up 50% of the container width */
        border-radius: 20%;
    }
</style>


<style>
    /* Advisors Section */
    .coll3 {
        float: left;
        width: 32.9%;
        padding-bottom: 10px;
        text-align: center;
    }

    /* Advisors Section */
    .coll9 {
        float: left;
        width: 11.11%;
        padding-bottom: 10px;
    }
</style>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
    <section id="research" class="container content-section">
        <div class="col-lg-10 col-lg-offset-1">
            <h2 style="text-align: center; margin-top: -150px;"> Research</h2>

<style>
    .research_box {
        padding: 10px;
        margin-bottom: 20px;
        background-color: #262626;
        width: 100%;
        border: 3px solid #3d3c3c;
    }

    .research_box:hover {
        border: 3px solid #7603d4;
        background-color: #3d3c3c;
        /* Adjust the border width and color as needed */
    }
</style>
<div style="padding-left: 5%;padding-right: 5%">
    <div style="width: 100%;padding: 8px;margin-bottom: 20px; text-align:center; font-size: large;">
        Some areas I'm currently excited about. If you want to chat about research or
        are interested in interning at MSR, feel free to reach out over email :)</div>

    <div class="research_box"><strong>ğŸ”
            Interpretability.</strong> I'm interested in <a href="https://arxiv.org/abs/2402.01761">rethinking
            interpretability</a> in the context of LLMs
        <br>
        <br>
        <a href="https://www.nature.com/articles/s41467-023-43713-1">augmented imodels</a> - use LLMs to build a
        transparent model<br>
        <a href="http://proceedings.mlr.press/v119/rieger20a.html">explanation penalization</a> - regularize
        explanations to align models with prior knowledge<br>
        <a href="https://proceedings.neurips.cc/paper/2021/file/acaa23f71f963e96c8847585e71352d6-Paper.pdf">adaptive
            wavelet distillation</a> - replace neural nets with simple, performant wavelet models
    </div>

    <div class="research_box">

        <strong>ğŸš— LLM steering. </strong>Interpretability tools can provide ways to better guide and use LLMs (without
        needing gradients!)
        <br>
        <br>
        <a href="https://arxiv.org/abs/2310.14034">tree prompting</a> - improve black-box few-shot text classification
        with decision trees<br>
        <a href="https://arxiv.org/abs/2311.02262">attention steering</a> / <a
            href="https://arxiv.org/abs/2409.10790">automatic attention steering</a> - guide LLMs by
        emphasizing specific input
        spans<br>
        <a href="https://arxiv.org/abs/2210.01848">interpretable autoprompting</a> - automatically find fluent
        natural-language prompts<br>
    </div>


    <div class="research_box">

        <strong>ğŸ§  Neuroscience. </strong> Since joining MSR, I've been focused on leveraging LLM interpretability
        to understand how the human brain represents language (using fMRI in collaboration with the <a
            href="https://www.cs.utexas.edu/~huth/index.html">Huth lab</a> at UT Austin).
        <br>
        <br>
        <a href="https://arxiv.org/abs/2405.16714">qa embeddings</a> - build interpretable fMRI encoding models by
        asking yes/no questions to LLMs<br>
        <a href="https://arxiv.org/abs/2305.09863">summarize &amp; score explanations</a> - generate natural-language
        explanations of fMRI encoding models
    </div>


    <div class="research_box"><strong>ğŸ’Š
            Healthcare.Â </strong>I'm also actively working on how we can improve clinical decision instruments by using
        the information contained across various sources in the medical literature (in collaboration with <a
            href="https://profiles.ucsf.edu/aaron.kornblith">Aaron Kornblith</a> at UCSF and the MSR <a
            href="https://www.microsoft.com/en-us/research/group/real-world-evidence/">Health Futures team</a>).
        <br>
        <br>
        <a href="https://arxiv.org/abs/2306.00024">clinical self-verification</a> - self-verification improves
        performance and interpretability of clinical information extraction<br>
        <a href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000076">clinical rule
            vetting</a> - stress testing a clinical decision instrument performance for intra-abdominal injury

    </div>

    <div style="width: 100%;padding: 8px;margin-bottom: 20px; text-align:center; font-size: large;">
        Across these areas, I'm interested in decision trees and how we can build flexible but accurate transparent
        models. I put a lot of my code into the <a href="https://github.com/csinva/imodels">imodels</a> and <a
            href="https://github.com/csinva/imodelsx">imodelsX</a> packages.</div>
</div>

<hr>

<script>
    $(document).ready(function () {
        $('#research_table').DataTable({
            "order": [[0, "desc"]],
            "aLengthMenu": [[6, -1], [6, "All"]],
            "pageLength": 6,
            dom: 'Bfrtip',
            buttons: [
                {
                    text: 'ğŸ” interpretability',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "ğŸ”").draw();
                    }
                },
                {
                    text: 'ğŸŒ€ deep learning',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "ğŸŒ€").draw();
                    }
                },
                {
                    text: 'ğŸŒ³ interpretable models',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "ğŸŒ³").draw();
                    }
                },
                {
                    text: 'ğŸ’» open-source ML',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "ğŸ’»").draw();
                    }
                },
                {
                    text: 'ğŸ§ ',
                    action: function (e, dt, node, config) {
                        var current_val = $(".dataTables_wrapper input").val();
                        var table = $('#research_table').DataTable();
                        table.search(current_val + "ğŸ§ ").draw();
                    }
                },
            ]
        });
    });
</script>

<table id="research_table" class="display" style="width:100%">
    <thead>
        <tr>
            <th>year</th>
            <th>title</th>
            <th>authors</th>
            <th>tags</th>
            <th>paper</th>
            <th>code</th>
            <th>misc</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td class="center">'24</td>
            <td>Crafting Interpretable Embeddings by Asking LLMs Questions
            </td>
            <td>benara*, singh*, morris, antonello, stoica, huth, & gao</td>
            <td class="med">ğŸ§ ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2405.16714">neurips</a></td>
            <td class="big"><a href="https://github.com/csinva/interpretable-embeddings"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Rethinking Interpretability in the Era of Large Language Models
            </td>
            <td>singh, inala, galley, caruana, & gao</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2402.01761">arxiv</a></td>
            <td class="big"></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning
            </td>
            <td>chen et al.</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2401.13986">arXiv</a></td>
            <td class="big"><a href="https://github.com/yandachen/explanation-consistency-finetuning"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Learning a Decision Tree Algorithm with Transformers
            </td>
            <td>zhuang et al.</td>
            <td class="med">ğŸ”ğŸŒ€ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/2402.03774">tmlr</a></td>
            <td class="big"><a href="https://github.com/EvanZhuang/MetaTree"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>

        <tr>
            <td class="center">'24</td>
            <td>Model Tells Itself Where to Attend: Faithfulness Meets Automatic Attention Steering
            </td>
            <td>zhang*, yu*, et al.</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2409.10790">arxiv</a></td>
            <td class="big"><a href="https://github.com/QingruZhang/AutoPASTA"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
            </td>
        </tr>

        <tr>
            <td class="center">'24</td>
            <td>Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs
            </td>
            <td>zhang et al.</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2311.02262">iclr</a></td>
            <td class="big"><a href="https://github.com/QingruZhang/PASTA"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'24</td>
            <td>Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries
            </td>
            <td>gero et al.</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2403.01002">arxiv</a></td>
            <td class="big"><a href="https://github.com/microsoft/attribute-structuring/"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Tree Prompting
            </td>
            <td>morris*, singh*, rush, gao, & deng</td>
            <td class="med">ğŸ”ğŸŒ€ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/2310.14034">emnlp</a></td>
            <td class="big"><a href="https://github.com/csinva/tree-prompt"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a
                    href="https://docs.google.com/presentation/d/17RqIjCGOaM19R_PFKTQMj5OGhmfpGccmxGW61ixzUPo/edit#slide=id.g21b26013510_0_4"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Augmenting Interpretable Models with LLMs during Training
            </td>
            <td>singh, askari, caruana, & gao</td>
            <td class="med">ğŸ”ğŸŒ€ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/2209.11799">nature communications</a></td>
            <td class="big"><a href="https://github.com/microsoft/augmented-interpretable-models"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a
                    href="https://docs.google.com/presentation/d/1ctUCnboHFtEsgJm8J7k66PtPn6xDLH-Y3aq_pNTFPBo/edit#slide=id.g23a629b547c_0_0"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Explaining black box text modules in natural language with language models
            </td>
            <td>singh*, hsu*, antonello, jain, huth, yu & gao</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2305.09863">neurips workshop</a></td>
            <td class="big"><a href="https://github.com/microsoft/automated-explanations"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a
                    href="https://docs.google.com/presentation/d/1qL_cATZWiwOg4EjgrQ93m2zEpNMYYdIUUqqMO1REbIk/edit#slide=id.g21b26013510_0_182"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'23</td>
            <td>Self-Verification Improves Few-Shot Clinical Information Extraction
            </td>
            <td>gero*, singh*, cheng, naumann, galley, gao, & poon</td>
            <td class="med">ğŸ”ğŸŒ€ğŸ’Š</td>
            <td class="center"><a href="https://arxiv.org/abs/2306.00024">icml workshop</a></td>
            <td class="big"><a href="https://github.com/microsoft/clinical-self-verification"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Explaining patterns in data with language models via interpretable autoprompting
            </td>
            <td>singh*, morris*, aneja, rush, & gao</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2210.01848">emnlp workshop</a></td>
            <td class="big"><a href="https://github.com/csinva/interpretable-autoprompting"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1_4X1IZMm6B621H5_81QZ5DuK9n4E-Vj8sVryVm1kjSE/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <!-- <tr>
            <td class="center">'22</td>
            <td>Interpretable deep learning for accurate molecular partner prediction in clathrin-mediated endocytosis
            </td>
            <td>singh*, li*, et al.</td>
            <td class="med">ğŸ”ğŸŒ€ğŸ¦ </td>
            <td class="center">in prep</td>
            <td class="big"><a href="https://github.com/Yu-Group/auxilin-prediction"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1sQXbFUTSEyrmDkovV8g759Wj8E9LBpATAVV1iweKeGo/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr> -->
        <!--    <tr>-->
        <!--        <td class="center">'22</td>-->
        <!--        <td>Group Probability-Weighted Tree Sums for Interpretable Modeling of Heterogeneous Data-->
        <!--        </td>-->
        <!--        <td>nasseri, singh, duncan, kornblith, & yu</td>-->
        <!--        <td class="med">ğŸ”ğŸŒ³ğŸ’Š</td>-->
        <!--        <td class="center"><a href="https://arxiv.org/abs/2205.15135">arXiv</a></td>-->
        <!--        <td class="big"><a href="https://github.com/Yu-Group/imodels-experiments"><i-->
        <!--                class="fa fa-github fa-fw"></i></a></td>-->
        <!--        <td class="med">-->
        <!--        </td>-->
        <!--    </tr>-->
        <tr>
            <td class="center">'22</td>
            <td>Stress testing a clinical decision instrument performance for intra-abdominal injury
            </td>
            <td>kornblith*, singh* et al.</td>
            <td class="med">ğŸ”ğŸŒ³ğŸ’Š</td>
            <td class="center"><a
                    href="https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000076">PLOS digital
                    health</a></td>
            <td class="big"><a href="https://github.com/csinva/iai-clinical-decision-rule"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1mxzGE0MkNZnzbIimDP8Kyq8oLfVSmHrOCKDPhiBPMz4/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Fast interpretable greedy-tree sums (FIGS)</td>
            <td>tan*, singh*, nasseri, agarwal, & yu</td>
            <td class="med">ğŸ”ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/2201.11931">arxiv</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1Gk5mEcSp6uePS72q-oF-GhXgLSbHfq2jWqMTKfwDaJw/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://csinva.io/imodels/figs.html"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>Hierarchical shrinkage for trees</td>
            <td>agarwal*, tan*, ronen, singh, & yu</td>
            <td class="med">ğŸ”ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/2202.00858">icml (spotlight)</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1inyZnryrs6dNO6VCn7ng6Rjc-XCkuagxx9YVHKJWqrM/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://csinva.io/imodels/shrinkage.html"><i class="fa fa-home fa-fw"></i></a>
                <!--            <a href="https://docs.google.com/presentation/d/1ReJ3Lqh4VZqpu6X6sP47f6Re6PvLIX9ZRAdjb8ZhFXE/present?slide=id.p"><i-->
                <!--                    class="fa fa-desktop fa-fw"></i></a>-->
            </td>
        </tr>
        <tr>
            <td class="center">'22</td>
            <td>VeridicalFlow: a python package for building trustworthy data science pipelines with PCS</td>
            <td>duncan*, kapoor*, agarwal*, singh*, & yu</td>
            <td class="med">ğŸ’»ğŸ”</td>
            <td class="center"><a href="https://joss.theoj.org/papers/10.21105/joss.03895">joss</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/Yu-Group/veridical-flow"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1ReJ3Lqh4VZqpu6X6sP47f6Re6PvLIX9ZRAdjb8ZhFXE/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>imodels: a python package for fitting interpretable models</td>
            <td>singh*, nasseri*, et al.</td>
            <td class="med">ğŸ’»ğŸ”ğŸŒ³</td>
            <td class="center"><a href="https://joss.theoj.org/papers/10.21105/joss.03192">joss</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/imodels"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1fpHo-MtIJntlIrYlQj0yK3spJ7Unf10CNTH-PG9LQ_A/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://bair.berkeley.edu/blog/2022/02/02/imodels/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Adaptive wavelet distillation from neural networks through interpretations</td>
            <td>ha, singh, et al.</td>
            <td class="med">ğŸ”ğŸŒ€ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/2107.09145">neurips</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/Yu-Group/adaptive-wavelet-distillation"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1YrzAir94D0KWewau34dZAXXPdATRuqeVf8Jt-o_wqG8/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://bair.berkeley.edu/blog/2021/09/28/wavelet/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Matched sample selection with GANs for mitigating attribute confounding</td>
            <td>singh, balakrishnan, & perona</td>
            <td class="med">ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/2103.13455">cvpr workshop</a></td>
            <!--            <td></td>-->
            <td class="big"><a href="https://github.com/csinva/matching-with-gans"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/19Z4TnHCDkNENutyKmE_kZBSJX4jMUam6DoH3HckkMrI/"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'21</td>
            <td>Revisiting complexity and the bias-variance tradeoff</td>
            <td>dwivedi*, singh*, yu & wainwright</td>
            <td class="med">ğŸŒ€</td>
            <td class="center"><a href="https://jmlr.org/papers/volume24/21-1133/21-1133.pdf">jmlr</a></td>
            <td class="big"><a href="https://github.com/csinva/mdl-complexity"><i class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med">
                <a href="https://drive.google.com/file/d/15hzAndJYNO3YsflL_RyB-4nQb2_KypK-/view?usp=sharing"><i
                        class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Curating a COVID-19 data repository and forecasting county-level death counts in the United States</td>
            <td>altieri et al.</td>
            <td class="med">ğŸ”ğŸ¦ </td>
            <td class="center"><a href="https://arxiv.org/abs/2005.07882">hdsr</a></td>
            <td class="big"><a href="https://github.com/Yu-Group/covid19-severity-prediction"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="https://docs.google.com/presentation/d/1nAYfBHj9qP-Qzpjho4dyMTx2Bc5Pccxu1VqIFiEaeYg/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <a href="https://covidseverity.com/"><i class="fa fa-home fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Transformation importance with applications to cosmology</td>
            <td>singh*, ha*, lanusse, boehm, liu & yu</td>
            <td class="med">ğŸ”ğŸŒ€ğŸŒŒ</td>
            <td class="center"><a href="https://arxiv.org/abs/2003.01926">iclr workshop (spotlight)</a></td>
            <td class="big"><a href="https://github.com/csinva/transformation-importance"><i
                        class="fa fa-github fa-fw"></i></a>
            </td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1mH1uG38qJg-ar0G-LiVPZWNKPO_2GiD-uayWM5AI-bo/"><i
                        class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'20</td>
            <td>Interpretations are useful: penalizing explanations to align neural networks with prior knowledge</td>
            <td>rieger, singh, murdoch & yu</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="http://proceedings.mlr.press/v119/rieger20a.html">icml</a>
            </td>
            <td class="big"><a href="https://github.com/laura-rieger/deep-explanation-penalization"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a href="https://icml.cc/virtual/2020/poster/5914"><i class="fa fa-desktop fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>Hierarchical interpretations for neural network predictions</td>
            <td>Singh*, Murdoch*, & Yu</td>
            <td class="med">ğŸ”ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/1806.05337">ICLR</a></td>
            <td class="big"><a href="https://github.com/csinva/acd"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1I6djTqVn6YGKqxvQk59-4C39LbE68mNQbX1Go5pzTH4/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <!--            <a href="/assets/write_ups/acd_18_bairday_poster.pdf"><i class="fa fa-picture-o fa-fw"></i></a>-->
            </td>
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>interpretable machine learning: definitions, methods, and applications</td>
            <td>Murdoch*, Singh*, et al.</td>
            <td class="med">ğŸ”ğŸŒ³ğŸŒ€</td>
            <td class="center"><a href="https://arxiv.org/abs/1901.04592">pnas</a></td>
            <td></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/13jbgFyYSSDaMUd2w4RY9GHteTcWJj1drS6_2sOkvnv4/"><i
                        class="fa fa-desktop fa-fw"></i></a>
                <!--            <a  href="/assets/write_ups/utokyo_19_interp_poster.pdf"><i  class="fa fa-picture-o fa-fw"></i></a></td>-->
        </tr>
        <tr>
            <td class="center">'19</td>
            <td>disentangled attribution curves for interpreting random forests and boosted trees</td>
            <td>devlin, singh, murdoch & yu</td>
            <td class="med">ğŸ”ğŸŒ³</td>
            <td class="center"><a href="https://arxiv.org/abs/1905.07631">arxiv</a></td>
            <td class="big"><a href="https://github.com/csinva/disentangled_attribution_curves"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td></td>
        </tr>
        <tr>
            <td class="center">'18</td>
            <td>large scale image segmentation with structured loss based deep learning for connectome reconstruction
            </td>
            <td>Funke*, Tschopp*, et al.</td>
            <td class="med">ğŸ§ ğŸŒ€</td>
            <td class="center"><a href="https://ieeexplore.ieee.org/abstract/document/8364622/">TPAMI</a></td>
            <td class="big"><a href="https://github.com/funkey/mala"><i class="fa fa-github fa-fw"></i></a></td>
            <td class="med">
                <a href="/assets/write_ups/singh_15_rf_segmentation.pdf"><i
                        class="fa fa-picture-o fa-fw"></i></a>
            </td>
        </tr>
        <tr>
            <td class="center">'18</td>
            <td>linearization of excitatory synaptic integration at no extra cost</td>
            <td>Morel, Singh, & Levy</td>
            <td class="med">ğŸ§ </td>
            <td class="center"><a href="http://rdcu.be/FDUo">J Comp Neuro</a></td>
            <td class="big"><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/"><i
                        class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'17</td>
            <td>a consensus layer V pyramidal neuron can sustain interpulse-interval coding</td>
            <td>Singh & Levy</td>
            <td class="med">ğŸ§ </td>
            <td class="center"><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0180839">Plos
                    One</a></td>
            <td class="big"><a href="https://senselab.med.yale.edu/modeldb/ShowModel.cshtml?model=237594"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1JriXXofysuXyfU4CeyNHJUTYSfa18R9Q3EhkCwFwh4g/"><i
                        class="fa fa-desktop fa-fw"></i></a></td>
        </tr>
        <tr>
            <td class="center">'17</td>
            <td>a constrained, weighted-l1 minimization approach for joint discovery of heterogeneous neural
                connectivity
                graphs
            </td>
            <td>Singh, Wang, & Qi</td>
            <td class="med">ğŸ§ </td>
            <td class="center"><a href="https://arxiv.org/abs/1709.04090">neurips Workshop</a></td>
            <td class="big"><a href="https://cran.r-project.org/web/packages/simule/index.html"><i
                        class="fa fa-github fa-fw"></i></a></td>
            <td class="med"><a
                    href="https://docs.google.com/presentation/d/1GO6lN5o2idozOUdnObXGnXKFbZiJiKKKkmx73uE4BAI/"><i
                        class="fa fa-desktop fa-fw"></i></a>,
                <!--            <a-->
                <!--                href="/assets/write_ups/wsimule_17_nips_poster.pdf"><i-->
                <!--                class="fa fa-picture-o fa-fw"></i></a>-->
            </td>
        </tr>
    </tbody>

</table>

<style>
    .big {
        font-size: large;
        text-align: center;
    }

    .med {
        font-size: medium;
        text-align: center;
    }

    td {
        text-align: left;
    }

    .center {
        text-align: center;
    }

    .dt-button span {
        color: white;
        font-family: Lora, "Helvetica Neue", Helvetica, Arial, sans-serif;
    }

    .dt-button {
        border-color: rgb(141, 141, 141) !important;
    }

    .dt-button:hover {
        border: 2px solid #5bc0de !important;
    }
</style>
        </div>
    </section>

    <section id="experience" class="container content-section">
        <div class="col-lg-64 col-lg-offset-0">
            <h2 style="text-align: center;margin-top: -150px;"> experience </h2>

<ul class="timeline">
    <li class="timeline-inverted">
        <div class="timeline-image">
            <img class="img-circle img-responsive" src="/assets/img/msft.svg" alt="">
        </div>
        <div class="timeline-panel">
            <div class="timeline-heading">
                <b style="font-size:x-large">microsoft research
                </b>
                <br><i style="font-size:large">Summer '22 - Present<br></i><br>
                <p> generating explanations with large language models for science & medicine, working in the <a
                        href="https://www.microsoft.com/en-us/research/group/deep-learning-group/">deep
                        learning group</a> </p>
            </div>
        </div>
    </li>

    <li class="timeline-inverted">
        <div class="timeline-image">
            <img class="img-circle img-responsive" src="/assets/img/paige.jpg" alt="">
        </div>
        <div class="timeline-panel">
            <div class="timeline-heading">
                <b style="font-size:x-large">healthcare ai
                </b>
                <br><i style="font-size:large">Summer '21-Summer '22, Spring '20, Summer '19<br></i><br>
                <p> worked at <a href="https://paige.ai/">paige ai</a> as a research scientist developing deep learning
                    models for
                    pathology -- also
                    worked at <a href="https://pacmed.ai/en/">pacmed ai</a> in 2019 and response4life covid
                    forecasting in 2020</p>
            </div>
        </div>
    </li>

    <li class="timeline-inverted">
        <div class="timeline-image">
            <img class="img-circle img-responsive" src="/assets/img/berkeley.png" alt="">
        </div>
        <div class="timeline-panel">
            <div class="timeline-heading">
                <b style="font-size:x-large">phd at uc berkeley
                </b>
                <br><i style="font-size:large">Fall '17-Spring '22<br></i><br>
                <p> researched interpretable machine learning, especially for neural networks and in scientific
                    applications, working in the <a href="https://www.stat.berkeley.edu/~binyu/Site/Welcome.html">bin
                        yu
                        group</a></p>
            </div>
        </div>
    </li>

    <li class="timeline-inverted">
        <div class="timeline-image">
            <img class="img-circle img-responsive" src="/assets/img/amzn.svg" alt="">
        </div>
        <div class="timeline-panel">
            <div class="timeline-heading">
                <b style="font-size:x-large">big tech internships
                </b>
                <br><i style="font-size:large">Summer '17, Summer '20<br></i><br>
                <p> worked on unsupervised semantic segmentation at <a href="https://ai.meta.com/research/">meta ai</a>,
                    and worked on causal fairness benchmarking
                    in computer vision at <a href="https://aws.amazon.com/machine-learning/ai-services/">aws</a></p>
            </div>
    </li>

    <li class="timeline-inverted">
        <div class="timeline-image">
            <img class="img-circle img-responsive" src="/assets/img/uva.png" alt="">
        </div>
        <div class="timeline-panel">
            <div class="timeline-heading">
                <div class="timeline-heading">
                    <b style="font-size:x-large">undergrad
                    </b>
                    <br><i style="font-size:large">summer '14- spring '17<br></i><br>
                    <p> worked on graphical models under <a href="https://www.cs.virginia.edu/yanjun/">Yanjun
                            Qi</a>
                        and on biophysical modeling under <a href="http://faculty.virginia.edu/levylab/">William
                            Levy</a> -- also spent 3 summers doing research at HHMI Janelia under <a
                            href="https://scholar.google.com/citations?user=V_NdI3sAAAAJ&hl=en&oi=ao">Srini Turaga</a>
                    </p>
                </div>
            </div>
    </li>


</ul>
<!--<hr>-->
<img src="/assets/img/lab.gif" class="img-responsive" alt=""
    style="margin-top:-0px; border-radius: 10%; width: 80%; margin-left: 10%;">
</br>
<div>
    <div class="coll9">
    </div>
    <div class="coll3">
        <p>
            I've been lucky to be advised by / collaborate with many amazing people
        </p>
        <ul class="list-items bullets">
            <li><a href="https://scholar.google.com/citations?user=CQ1cqKkAAAAJ&hl=en&oi=ao">jianfeng gao</a> ğŸ¤– (msr
                manager)</li>
            <li><a href="https://scholar.google.com/citations?user=xT19Jc0AAAAJ&hl=en&oi=ao">bin yu</a> ğŸ¤– (phd advisor)
            </li>
            <li><a href="https://scholar.google.com/citations?user=l6nlkhMAAAAJ&hl=en&oi=ao">aaron kornblith</a> ğŸ’Š</li>
            <li><a href="https://scholar.google.com/citations?user=JNXWWkIAAAAJ&hl=en&oi=ao">alex huth</a> ğŸ§ </li>
            <li><a href="https://scholar.google.com/citations?user=nxwNAEgAAAAJ&hl=en&oi=ao">gokul upadhyayula</a> ğŸ¦ 
            </li>
            <li><a href="https://scholar.google.com/citations?user=eXKdSu0AAAAJ&hl=en&oi=ao">yanjun qi</a> ğŸ¤–</li>
            <li><a href="https://scholar.google.com/citations?user=fRDCooIAAAAJ&hl=en&oi=ao">francois lanusse</a> ğŸŒŒ
            </li>
            <li><a href="https://scholar.google.com/citations?user=V_NdI3sAAAAJ&hl=en&oi=ao">srini turaga</a> ğŸ§ </li>
            <li><a href="https://scholar.google.com/citations?user=j29kMCwAAAAJ&hl=en&oi=aol">pietro perona</a> ğŸ¤–</li>
            <li><a href="https://med.virginia.edu/faculty/faculty-listing/wbl/">william levy</a> ğŸ§ </li>
        </ul>
    </div>
    <div class="coll9">
    </div>
    <div class="coll3">
        <p>
            It has been my pleasure to help advise some incredible students
        </p>
        MSR PhD interns
        <br>
        <ul class="list-items bullets">
            <li><a href="https://www.linkedin.com/in/yufan-zhuang/">yufan zhuang</a></li>
            <li><a href="https://yandachen.github.io">yanda chen</a></li>
            <li><a href="https://www.linkedin.com/in/qingru-zhang-4b789a187/">qingru zhang</a></li>
        </ul>
        <br>
        Berkeley undergrad/MS students
        <ul class="list-items bullets">
            <li><a href="https://www.linkedin.com/in/nasseri/">keyan nasseri</a> ('20-'22)</li>
            <li><a href="https://www.linkedin.com/in/ssaxena00/">sahil saxena</a> ('22)</li>
            <li><a href="https://www.linkedin.com/in/saarimrahman/">saarim rahman</a> ('21-'22)</li>
            <li><a href="https://www.linkedin.com/in/rush-kapoor/">rush kapoor</a> ('21-'22)</li>
            <li><a href="https://www.linkedin.com/in/summer-devlin-5454b7154/">summer devlin</a> ('18-'19)</li>
            <li><a href="https://www.linkedin.com/in/chris-lu-37471b119/">chris lu</a> ('17-'18)</li>
        </ul>
    </div>
    <div class="coll9">
    </div>
</div>
        </div>
    </section>
</body>

</html>